{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "051fd701",
   "metadata": {},
   "source": [
    "### Installing\n",
    "\n",
    "Ensure that you have Homebrew installed on your macOS system.\n",
    "\n",
    "```bash\n",
    "brew install openjdk@17\n",
    "brew link --force --overwrite openjdk@17\n",
    "```\n",
    "\n",
    "Modify your shell configuration file (e.g., `~/.bash_profile`, `~/.zshrc`, etc.) to set the environment variables:\n",
    "```bash\n",
    "export JAVA_HOME=$(/usr/libexec/java_home -v 17)\n",
    "export PATH=$JAVA_HOME/bin:$PATH\n",
    "```\n",
    "\n",
    "Install AWS dependencies:\n",
    "```bash\n",
    "pyspark --packages org.apache.hadoop:hadoop-aws:3.3.2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22486d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from dotenv import load_dotenv\n",
    "from sedona.spark import SedonaContext\n",
    "import os\n",
    "from pyspark.sql.functions import col, explode\n",
    "from datetime import datetime, date\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, ArrayType, MapType\n",
    "from tqdm import tqdm\n",
    "from sedona.sql.types import GeometryType\n",
    "from pathlib import Path\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c8c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!spark-submit --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd83f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = Path('../_cache')\n",
    "LOGS_DIR = Path('../_logs')\n",
    "DATASET_DIR = Path('../datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0211d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedona = SedonaContext.builder() \\\n",
    "    .appName(\"BDCCFinalExam\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"7g\") \\\n",
    "    .config(\"spark.executor.memory\", \"7g\") \\\n",
    "    .config(\"spark.storage.memoryFraction\",\"0.4\") \\\n",
    "    .config(\"spark.memory.fraction\",\"0.6\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider') \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", os.getenv(\"AWS_ACCESS_KEY_ID\")) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", os.getenv(\"AWS_SECRET_ACCESS_KEY\")) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.fast.upload\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-Dcom.amazonaws.services.s3.enableV4=true\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Dcom.amazonaws.services.s3.enableV4=true\") \\\n",
    "    .config(\"spark.jars.packages\",\n",
    "            'org.apache.sedona:sedona-spark-shaded-3.3_2.12:1.7.1,'\n",
    "            \"org.apache.hadoop:hadoop-aws:3.2.0,\"\\\n",
    "            'org.datasyslab:geotools-wrapper:1.7.1-28.5,'\\\n",
    "            \"com.amazonaws:aws-java-sdk-bundle:1.11.375\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e14865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.register import SedonaRegistrator\n",
    "from pyspark.sql.functions import input_file_name\n",
    "\n",
    "\n",
    "# Register Sedona UDTs and functions\n",
    "SedonaRegistrator.registerAll(sedona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8b1b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_dates = [\n",
    "    date(year, month, 1)\n",
    "    for year in range(2025, 2017, -1)\n",
    "    for month in (1, 4, 7, 10)\n",
    "]\n",
    "\n",
    "# filter out snapshot dates that are in future\n",
    "snapshot_dates = [d for d in snapshot_dates if d <= date.today()]\n",
    "\n",
    "print(\"Snapshot dates:\")\n",
    "for snapshot_date in snapshot_dates:\n",
    "    print(snapshot_date.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc5ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_TO_RETAIN = ['building','amenity','leisure','public_transport','office','shop','tourism']\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"crs\", StructType([\n",
    "        StructField(\"properties\", StructType([\n",
    "            StructField(\"name\", StringType(), True)\n",
    "        ]), True),\n",
    "        StructField(\"type\", StringType(), True)\n",
    "    ]), True),\n",
    "\n",
    "    StructField(\"features\", ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"geometry\", GeometryType(), True), \n",
    "            StructField(\"properties\", StructType([\n",
    "                StructField(\"amenity\", StringType(), True),\n",
    "                StructField(\"building\", StringType(), True),\n",
    "                StructField(\"element\", StringType(), True),\n",
    "                StructField(\"id\", LongType(), True),\n",
    "                StructField(\"leisure\", StringType(), True),\n",
    "                StructField(\"name\", StringType(), True),\n",
    "                StructField(\"office\", StringType(), True),\n",
    "                StructField(\"province\", StringType(), True),\n",
    "                StructField(\"public_transport\", StringType(), True),\n",
    "                StructField(\"region\", StringType(), True),\n",
    "                StructField(\"shop\", StringType(), True),\n",
    "                StructField(\"tourism\", StringType(), True)\n",
    "            ]), True),\n",
    "            StructField(\"type\", StringType(), True)\n",
    "        ])\n",
    "    ), True),\n",
    "\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"type\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbd44c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_features = {}\n",
    "for snapshot_date in tqdm(snapshot_dates, desc=\"Processing snapshot dates\"):\n",
    "    snapshot_date_str = snapshot_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    df = sedona.read.format(\"geojson\") \\\n",
    "        .option(\"multiLine\", \"true\") \\\n",
    "        .schema(schema) \\\n",
    "        .load(f\"s3a://amenities-dataset/amenities_v2/date={snapshot_date_str}/\")\n",
    "\n",
    "    exploded_df = df.select(explode(\"features\").alias(\"feature\")).repartition(8).persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "    # Select all relevant properties in one pass\n",
    "    values_df = exploded_df.select(\n",
    "        *[col(f\"feature.properties.{feature}\").alias(feature) for feature in FEATURES_TO_RETAIN]\n",
    "    )\n",
    "\n",
    "    for feature in FEATURES_TO_RETAIN:\n",
    "        distinct_values = (\n",
    "            values_df\n",
    "            .select(feature)\n",
    "            # .filter(col(feature).isNotNull())\n",
    "            .distinct()\n",
    "            .rdd.flatMap(lambda x: x)\n",
    "            .collect()\n",
    "        )\n",
    "\n",
    "        unique_features.setdefault(feature, set()).update(distinct_values)\n",
    "\n",
    "    exploded_df.unpersist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "serializable_features = {k: list(v) for k, v in unique_features.items()}\n",
    "\n",
    "with open(DATASET_DIR / \"unique_features.json\", \"w\") as f:\n",
    "    json.dump(serializable_features, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdcc-final-exam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
